{"cells":[{"source":"_add text here_","metadata":{},"id":"7607bdb2-1707-4361-a984-1c443fe84370","cell_type":"markdown"},{"source":"# Write and run code here\n# Import data here\ngoogle = pd.read_csv('google.csv', parse_dates=['Date'], index_col='Date')\n\n# Set data frequency to business daily\ngoogle = google.asfreq('D')\n\n# Create 'lagged' and 'shifted'\ngoogle['lagged'] = google.Close.shift(periods=-90)\ngoogle['shifted'] = google.Close.shift(periods=90)\n\n# Plot the google price series\ngoogle.plot()\nplt.show()\n","metadata":{},"id":"7f26dd6a-20aa-4d19-8d3f-b8f64fba1821","cell_type":"code","execution_count":1,"outputs":[]},{"source":"# Created shifted_30 here\nyahoo['shifted_30'] = yahoo.price.shift(periods=30)\n\n# Subtract shifted_30 from price\nyahoo['change_30'] = yahoo.price.sub(yahoo['shifted_30'] )\n# Get the 30-day price difference\nyahoo['diff_30'] = yahoo.price.diff(periods=30)\n\n# Inspect the last five rows of price\nprint(yahoo.tail(5))\n\n# Show the value_counts of the difference between change_30 and diff_30\nprint(yahoo.change_30.sub(yahoo.diff_30).value_counts())\n","metadata":{},"cell_type":"code","id":"0fae2d53-8d13-40dd-b435-dbbd4e9dc903","execution_count":null,"outputs":[]},{"source":"","metadata":{},"cell_type":"code","id":"1a55af02-37c8-48dd-be75-77824f3a5e53","execution_count":null,"outputs":[]},{"source":"# Create daily_return\ngoogle['daily_return'] = google.Close.pct_change(periods=1).mul(100)\n\n# Create monthly_return\ngoogle['monthly_return'] = google.Close.pct_change(periods=30).mul(100)\n\n# Create annual_return\ngoogle['annual_return'] = google.Close.pct_change(periods=360).mul(100)\n\n# Plot the result\ngoogle.plot(subplots=True)\nplt.show()\n","metadata":{},"cell_type":"code","id":"3eaaf2bb-10b0-4f97-93ec-584b250c29a5","execution_count":null,"outputs":[]},{"source":"# Create tickers\ntickers = ['MSFT', 'AAPL']\n\n# Import stock data here\nstocks = pd.read_csv('msft_aapl.csv', parse_dates=['date'], index_col='date')\n\n# Import index here\nsp500 = pd.read_csv('sp500.csv', parse_dates=['date'], index_col='date')\n\n# Concatenate stocks and index here\ndata = pd.concat([stocks, sp500], axis=1).dropna()\n\n# Normalize data\nnormalized = data.div(data.iloc[0]).mul(100)\n\n# Subtract the normalized index from the normalized stock prices, and plot the result\ndiff = normalized[tickers].sub(normalized['SP500'], axis=0)\ndiff.plot()\nplt.show()","metadata":{},"cell_type":"code","id":"d8679afc-63a9-4d92-a5c8-809ae83807ee","execution_count":null,"outputs":[]},{"source":"# Set start and end dates\nstart = '2016-1-1'\nend = '2016-2-29'\n\n# Create monthly_dates here\nmonthly_dates = pd.date_range(start, end, freq='M')\n\n# Create and print monthly here\nmonthly = pd.Series(data=[1,2], index=monthly_dates)\nprint(monthly)\n\n# Create weekly_dates here\nweekly_dates = pd.date_range(start, end, freq='W')\n\n# Print monthly, reindexed using weekly_dates\nprint(monthly.reindex(weekly_dates))\nprint(monthly.reindex(weekly_dates, method='bfill'))\nprint(monthly.reindex(weekly_dates, method='ffill'))\n","metadata":{},"cell_type":"code","id":"486d8822-1e28-45aa-bbd6-7319ed3999b7","execution_count":null,"outputs":[]},{"source":"'''We have already imported pandas as pd and matplotlib.pyplot as plt.\n\nUse pd.read_csv() to import 'unemployment.csv', creating a DateTimeIndex from the 'date' column using parse_dates and index_col, and assign the result to data.\nConvert data to weekly frequency using .asfreq() with the alias 'W' and show the first five rows.\nConvert again to weekly frequency, adding the option 'bfill' and show the first five rows.\nCreate weekly series, now adding the option 'ffill', assign to weekly_ffill and show the first five rows.\nPlot weekly_ffill starting in 2015.'''\n\n# Import data here\ndata = pd.read_csv('unemployment.csv', parse_dates=['date'], index_col='date')\n\n# Show first five rows of weekly series\nprint(data.asfreq('W').head())\n\n# Show first five rows of weekly series with bfill option\nprint(data.asfreq('W', method='bfill').head())\n\n# Create weekly series with ffill option and show first five rows\nweekly_ffill = data.asfreq('W', method='ffill')\nprint(weekly_ffill.head())\n\n# Plot weekly_fill starting 2015 here \nweekly_ffill.loc['2015':].plot()\nplt.show()\n-2","metadata":{},"cell_type":"code","id":"0d936111-eede-46e5-809f-53da176c4c5d","execution_count":null,"outputs":[]},{"source":"#October 30th.\n# Import & inspect data here\ndata = pd.read_csv('debt_unemployment.csv', parse_dates=['date'], index_col='date')\nprint(data.info())\n\n# Interpolate and inspect here\ninterpolated = data.interpolate()\nprint(interpolated.info())\n\n# Plot interpolated data here\ninterpolated.plot(secondary_y='Unemployment')\nplt.show()\n","metadata":{},"cell_type":"code","id":"582d332c-01ea-48ca-bc51-320385d04c39","execution_count":null,"outputs":[]},{"source":"# Import and inspect data here\nozone = pd.read_csv('ozone.csv',parse_dates=['date'], index_col='date')\nprint(ozone.info())\n\n# Calculate and plot the weekly average ozone trend\nozone.resample('W').mean().plot()\n# ozone.plot()\nplt.show()\n\n# Calculate and plot the monthly average ozone trend\nozone.resample('M').mean().plot()\n# ozone.plot()\nplt.show()\n\n# Calculate and plot the annual average ozone trend\nozone.resample('A').mean().plot()\nplt.show()\n\n#############################################################################\n# Import and inspect data here\nstocks = pd.read_csv('stocks.csv', parse_dates=['date'], index_col='date')\nprint(stocks.info())\n\n# Calculate and plot the monthly averages\nmonthly_average = stocks.resample('M').mean()\nmonthly_average.plot(subplots=True)\nplt.show()\n","metadata":{},"cell_type":"code","id":"f0f5756b-ec0e-4857-b029-ba7c566979ed","execution_count":null,"outputs":[]},{"source":"# Import and inspect gdp_growth here\ngdp_growth = pd.read_csv('gdp_growth.csv', parse_dates=['date'], index_col='date')\nprint(gdp_growth.info())\n\n# Import and inspect djia here\ndjia = pd.read_csv('djia.csv', parse_dates=['date'], index_col='date')\nprint(djia.info())\n\n# Calculate djia quarterly returns here \ndjia_quarterly = djia.resample('QS').first()\ndjia_quarterly_return = djia_quarterly.pct_change().mul(100)\n\n# Concatenate, rename and plot djia_quarterly_return and gdp_growth here \ndata = pd.concat([gdp_growth, djia_quarterly_return], axis=1)\ndata.columns = ['gdp', 'djia']\ndata.plot()\nplt.show()\n\n###########################################################\n# Import data here\nsp500 = pd.read_csv('sp500.csv', parse_dates=['date'], index_col='date')\nsp500.info()\n# Calculate daily returns here\ndaily_returns = sp500.squeeze().pct_change()\n\n# Resample and calculate statistics\nstats = daily_returns.resample('M').agg(['mean', 'median', 'std'])\n\n# Plot stats here\nstats.plot()\nplt.show()\n\n","metadata":{},"cell_type":"code","id":"0b558dc5-56ab-4819-a6da-6bbfd8009b12","execution_count":null,"outputs":[]},{"source":"# Import and inspect ozone data here\ndata = pd.read_csv('ozone.csv', parse_dates=['date'], index_col='date')\nprint(data.info())\n\n# Calculate 90d and 360d rolling mean for the last price\ndata['90D'] = data.Ozone.rolling(window='90D').mean()\ndata['360D'] = data.Ozone.rolling(window='360D').mean()\n\n# Plot data\ndata['2010':].plot()\nplt.title('New York City')\nplt.show()\n","metadata":{},"cell_type":"code","id":"80409d16-184c-4eb3-a5d4-ca6140ef445b","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataCamp Workspace"},"nbformat":4,"nbformat_minor":5}