{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m bucket_10, bucket_30, bucket_60, bucket_90, bucket_120, bucket_over \u001b[38;5;241m=\u001b[39m [], [], [], [], [], []\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Calculate differences\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m df_diff \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mdiff(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Populate the buckets\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, row \u001b[38;5;129;01min\u001b[39;00m days_to_expiration_df\u001b[38;5;241m.\u001b[39miterrows():\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Example DataFrame creation\n",
    "# df = pd.DataFrame(...)\n",
    "# days_to_expiration_df = pd.DataFrame(...)\n",
    "\n",
    "# Assuming df and days_to_expiration_df are defined as per your context\n",
    "\n",
    "# Initialize lists for each bucket\n",
    "bucket_10, bucket_30, bucket_60, bucket_90, bucket_120, bucket_over = [], [], [], [], [], []\n",
    "\n",
    "# Calculate differences\n",
    "df_diff = df.diff(1)\n",
    "\n",
    "# Populate the buckets\n",
    "for i, row in days_to_expiration_df.iterrows():\n",
    "    base_vol = df_diff.loc[i, '31/05/2024']\n",
    "    for col, c in row.items():\n",
    "        if np.isnan(c):\n",
    "            continue\n",
    "        \n",
    "        c_vol = df_diff.loc[i, col]\n",
    "        pair = (1, base_vol, c_vol, c)\n",
    "        \n",
    "        if c < 11:\n",
    "            bucket_10.append(pair)\n",
    "        elif c < 31:\n",
    "            bucket_30.append(pair)\n",
    "        elif c < 61:\n",
    "            bucket_60.append(pair)\n",
    "        elif c < 91:\n",
    "            bucket_90.append(pair)\n",
    "        elif c < 121:\n",
    "            bucket_120.append(pair)\n",
    "        else:\n",
    "            bucket_over.append(pair)            \n",
    "\n",
    "bucket_10 = pd.DataFrame(bucket_10, columns = ['constant', 'year', 'less10', 'days'])        \n",
    "bucket_30 = pd.DataFrame(bucket_30, columns = ['constant', 'year', 'less30', 'days'])  \n",
    "bucket_60 = pd.DataFrame(bucket_60, columns = ['constant', 'year', 'less60', 'days'])  \n",
    "bucket_90 = pd.DataFrame(bucket_90, columns = ['constant', 'year', 'less90', 'days'])  \n",
    "\n",
    "# Example of regression with statsmodels\n",
    "def run_regression(bucket_df):\n",
    "    X = bucket_df[['constant', 'year']]  # Independent variables\n",
    "    y = bucket_df.iloc[:, 2]  # Dependent variable (third column of each bucket DataFrame)\n",
    "    model = sm.OLS(y, X)\n",
    "    results = model.fit()\n",
    "    return results.params\n",
    "\n",
    "# Run regression for each bucket\n",
    "b10_results = run_regression(bucket_10)\n",
    "b30_results = run_regression(bucket_30)\n",
    "b60_results = run_regression(bucket_60)\n",
    "b90_results = run_regression(bucket_90)\n",
    "\n",
    "print(b10_results)\n",
    "print(b30_results)\n",
    "print(b60_results)\n",
    "print(b90_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward\u001b[39m(\u001b[38;5;28mself\u001b[39m, target: \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mndarray, out: np\u001b[38;5;241m.\u001b[39mndarray, loss_fn) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m      3\u001b[0m \u001b[38;5;250m     \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m        One backward pass through all the layers of the neural network.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m        During this phase, we calculate the gradients of the loss with respect to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m        the loss of the model given the training inputs and targets\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     22\u001b[0m      \u001b[38;5;66;03m# Compute the initial gradient, based on your loss function logic.\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "def backward(self, target: np.ndarray, out: np.ndarray, loss_fn) -> float:\n",
    "     \n",
    "     \"\"\"\n",
    "        One backward pass through all the layers of the neural network.\n",
    "        During this phase, we calculate the gradients of the loss with respect to\n",
    "        each of the parameters of the entire neural network. Most of the heavy\n",
    "        lifting is done by the `backward` methods of the layers, so this method\n",
    "        should be relatively simple. Also, make sure to compute the loss in this\n",
    "        method and NOT in `self.forward`.\n",
    "        \n",
    "        Note: Both input arrays have the same shape.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        target: the targets we are trying to fit to (e.g., training labels)\n",
    "        out: the predictions of the model on training data\n",
    "        Returns\n",
    "        -------\n",
    "        the loss of the model given the training inputs and targets\n",
    "    \"\"\"\n",
    "     \n",
    "     # Compute the initial gradient, based on your loss function logic.\n",
    "     gradient = (out - target) / out.shape[0]\n",
    "     # Backpropagate through the network's layers.\n",
    "     for layer in reversed(self.layers):\n",
    "        gradient = layer.backward(gradient)\n",
    "    # Update the optimizer (assuming that the optimizer has update method)\n",
    "     for layer in self.layers:\n",
    "        self.optimizer.update(layer.parameters, layer.gradient)\n",
    "    \n",
    "    # Compute loss: we assume that the self.loss initialized in the __init__ method will handle loss.\n",
    "     loss = self.loss\n",
    "     return loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Forage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
